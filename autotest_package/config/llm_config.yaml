# model_provider: "openai"  # Options: openai, groq, anthropic, etc.
# model_settings:
#   openai:
#     analysis_model: "gpt-4.1-2025-04-14" # For page analysis and test generation
#     selenium_model: "gpt-4.1-mini-2025-04-14" # For script generation
#     temperature: 0.2

# model_provider: "groq"  # Options: openai, groq, anthropic, etc.
# model_settings:
#   groq:
#     analysis_model: "meta-llama/llama-4-scout-17b-16e-instruct"   # For page analysis and test generation
#     selenium_model: "meta-llama/llama-4-maverick-17b-128e-instruct"   # For script generation
#     temperature: 0.2

# model_provider: "google-gemini"  # Options: openai, groq, anthropic, etc.
# model_settings:
#   google-gemini:
#     analysis_model: "gemini-2.0-flash" # For page analysis and test generation
#     selenium_model: "gemini-1.5-pro" # For script generation
#     temperature: 0.1

# Provider configurations - all available
providers:
  openai:
    analysis_model: "gpt-4.1-2025-04-14"
    selenium_model: "gpt-4.1-2025-04-14"
    temperature: 0.2
  
  groq:
    analysis_model: "meta-llama/llama-4-scout-17b-16e-instruct"
    selenium_model: "meta-llama/llama-4-maverick-17b-128e-instruct"
    temperature: 0.2
  
  google-gemini:
    analysis_model: "gemini-2.5-flash"
    selenium_model: "gemini-2.5-flash"
    temperature: 0.1

  anthropic:
    analysis_model: "claude-3-7-sonnet-latest"
    selenium_model: "claude-sonnet-4-20250514" 
    temperature: 0.2

  ollama:
    analysis_model: "qwen2.5-coder:7b-instruct"
    selenium_model: "qwen2.5-coder:7b-instruct"
    temperature: 0.2
