llm_page_analysis:
  system: "You are a web page analyst. Extract structural and functional metadata from HTML."
  user: |
    Analyze this web page structure and return JSON metadata:
    {{
        "auth_requirements": {{
            "auth_required": boolean,
            "auth_type": "login|registration|none",
            "auth_fields": [
                {{
                    "name": "field_name",
                    "type": "email|text|password",
                    "required": boolean,
                    "selector": "css_selector_or_xpath",
                    "validation_indicators": [
                        {{
                            "type": "class|style|element|attribute|alert",
                            "value": "class_name|style_property|element_selector|attribute_name|alert_message",
                            "description": "e.g., 'red border', 'exclamation mark', 'pattern attribute', 'JS alert for invalid input'"
                        }}
                    ],
                    "default_value": "visible_default_value_if_any"
                }}
            ],
            "credentials_hint": "text_or_element_containing_credentials"
        }},
        "contact_form_fields": [
            {{
                "id": "form_id",
                "action": "form_action_url",
                "method": "get|post",
                "fields": [
                    {{
                        "name": "field_name",
                        "type": "text|email|password|checkbox|radio|select|file",
                        "required": boolean,
                        "selector": "css_selector_or_xpath",
                        "validation_indicators": [
                            {{
                                "type": "class|style|element|attribute|alert",
                                "value": "class_name|style_property|element_selector|attribute_name|alert_message",
                                "description": "e.g., 'red border', 'exclamation mark', 'pattern attribute', 'JS alert for invalid input'"
                            }}
                        ]
                    }}
                ],
                "submit_button": {{
                    "text": "button_text",
                    "selector": "css_selector_or_xpath"
                }}
            }}
        ],
        "interactive_elements": [
            {{
                "type": "button|link|menu|dropdown|accordion",
                "text": "element_text_or_image_alt",
                "selector": "css_selector_or_xpath",
                "action": "click|hover|submit",
                "expected_outcome": "e.g., 'redirects to /path', 'opens modal', 'expands menu'",
                "sub_elements": [
                    {{
                        "type": "button|link|menu|dropdown",
                        "text": "sub_element_text_or_image_alt",
                        "selector": "sub_element_selector",
                        "action": "click|hover",
                        "expected_outcome": "e.g., 'redirects to /to_that_page_name', 'expands submenu'"
                    }}
                ]
            }}
        ],
        "ui_validation_indicators": [
            {{
                "element_selector": "css_selector_or_xpath",
                "validation_type": "attribute|masking|state_change",
                "validation_value": "attribute_name|masked|state_description",
                "description": "e.g., 'pattern attribute present', 'input is masked', 'checkbox toggles visually'"
            }}
        ],
        "main_content": "Brief description of main content areas",
        "key_actions": ["list of primary user actions"],
        "content_hierarchy": {{
            "primary_sections": ["section1", "section2"],
            "subsections": ["subsection1", "subsection2"]
        }},
        "security_indicators": ["https", "captcha", "csrf_token", "otp", "file_upload"]
    }}

    Current page HTML:
    {page_source}

    Focus on:
    - All forms and their fields, including types, requirements, and submission details
    - Forms should be categorized based on their purpose:
      - **Login/Registration forms**: Place under `auth_requirements` if they involve authentication (e.g., username, password fields) only in the page provided.
        - Do not consider already logged in user under this category
      - **Contact forms**: Place under `contact_form_fields` only if they are explicitly for contact purposes (e.g., name, email, message fields). Identify contact forms by:
        - Field names like 'name', 'email', 'message', 'subject', or similar
        - Form action URLs containing '/contact', '/support', '/inquiry', or similar/related endpoints
        - Contextual clues like labels or nearby text (e.g., 'Contact Us', 'Get in Touch')
      - **Other forms** (e.g., search forms, filters): Place under `interactive_elements` with `type: form`, including a `form_details` object with fields and submit button info. Examples include:
        - Search forms (e.g., action='/search', fields like 'q' or 'query')
        - Filter forms (e.g., fields like 'sort', 'category')
    - For all forms/elements, include only visible, non-hidden input fields (e.g., exclude `type='hidden'` unless they are critical for functionality, like CSRF tokens or security-related fields). Hidden fields should be omitted unless explicitly tied to user-facing actions or security (e.g., `csrf_token`).
    - Interactive elements like buttons, links, menus, and their actions, including all sub-elements (e.g., menu items)
    - For links that contain images, set the "text" field to the image's `alt` text, or a descriptive phrase like "Logo image" if no `alt` is present
    - Include "expected_outcome" for each interactive element, such as "redirects to /path" for links, based on the `href` attribute or other indicators
    - UI elements indicating validation states (e.g., classes like 'is-invalid', style changes like 'border-color: red', icons like '!', JS alerts, attributes like 'pattern')
    - Semantic HTML structure
    - User interaction patterns (e.g., clicking menus to expand or redirect)
    - Content organization
    - Security features, including https, captcha, csrf_token, OTP and file upload fields
    - Specifically look for:
      - Classes or attributes indicating invalid states (e.g., 'is-invalid', 'error')
      - CSS changes (e.g., border colors), inline elements (e.g., '!' icons), or JS alerts for validation
      - Full menu structures, including all sub-items, with expected actions (e.g., redirection URLs)
      - Page-specific validation behaviors beyond explicit error messages (e.g., masking, pattern enforcement)
      - Any visible default credentials or hints for login (e.g., text like 'Username: testuser' or 'Password: testpass123')
    - For accordions:
      - Only classify elements as "accordion" if they have expandable/collapsible behavior, confirmed by:
        - JavaScript event listeners (e.g., `click` handlers toggling visibility, inferred from classes like `toggle` or `collapse`)
        - CSS classes indicating toggling (e.g., `collapse`, `accordion`, `expand`)
        - HTML structure with headers and collapsible content (e.g., `<div class="accordion">` with child `<div class="collapse">`)
      - Do not classify an element as an accordion based solely on its label (e.g., "Filters") or static structure (e.g., nested divs without toggling behavior). Verify behavior from HTML attributes, classes, or structure.

generate_tests:
  system: |
    You are a senior QA engineer. Output MUST be valid JSON format as specified. Create specific test cases based on actual page elements and structure.
    Generate comprehensive test cases covering both regular functionality and authentication flows when present.
    Ensure valid JSON output.
  user: |
    Generate test cases in VALID JSON format with specific actual current page elements.
    Generate comprehensive test cases including both regular and authentication tests.
    Output ONLY valid JSON using this EXACT structure:
    {{
      "test_cases": [
          {{
              "name": "Test name",
              "type": "functional|auth-positive|auth-negative|ui-validation",
              "test_case_type": "auto-generated",
              "steps": ["step1", "step2"],
              "selectors": {{
                  "element1": "css_selector_or_xpath",
                  "element2": "xpath"
              }},
              "validation": "Expected outcome",
              "test_data": {{
                  "field_name": "specific_value"
              }}
          }}
        ]
    }}

    Current page elements (Page Structure Metadata):
    {page_metadata}

    {prompt_suffix}

    Use selectors from this page structure:
    {{
        "title": "{title}",
        "forms": {forms},
        "buttons": {buttons}
    }}

    Current page URL: {url}
    Current Page HTML: {page_source}

    Guidelines:
    1. Create tests SPECIFIC to these page elements
    2. Functional tests for core page elements and ALL interactive elements (e.g., every menu and sub-menu option)
    3. For interactive elements with "expected_outcome" like "redirects to /path", generate navigation test cases with "validation": "Page redirects to /path"
    4. Cover functional, UI validation checks, and security aspects
    5. Prioritize main user flows
    6. Include edge cases for observed input types
    7. Include both positive and negative test cases
    8. Include the same key names as in the test data provided for field_name in test_data, keeping the order constant
    9. For authentication tests (if applicable):
        - Valid credential submission (auth-positive): Use default credentials if provided in metadata
        - Invalid format tests (auth-negative): Validate EITHER Bootstrap class (e.g., 'is-invalid') OR error message/alert, whichever is present. Use partial matching for error messages (e.g., contains 'required', 'invalid')
        - Missing required fields (auth-negative): Handle ALL missing input scenarios here
        - Security validations
    10. For UI validation tests:
        - DO NOT generate ui-validation tests for missing inputs or invalid formats; these are covered by auth-negative tests
        - Focus ONLY on unique visual or behavioral feedback NOT covered by auth-negative tests, such as:
          - Password masking (e.g., type='password' hides input)
          - Presence of validation attributes (e.g., 'pattern' attribute)
          - UI state changes (e.g., checkbox toggle visuals)
          - Error message styling (e.g., red text) for invalid inputs, but only if validation_indicators include styling info in metadata
          - CSS property checks for key UI elements to ensure consistent and correct styling across the page:
            - Text elements (headings, paragraphs, labels): Check `font-family`, `font-size`, `font-weight`, `color`, `text-align`, `line-height`
            - Form elements (inputs, buttons, selects): Check `border`, `border-radius`, `background-color`, `padding`, `margin`, `width`, `height`, `font-size`, `color`
            - Tables: Check `border-collapse`, `border-spacing`, `border`, `width`, `height`, `padding` (for cells), `background-color` (for headers/rows)
            - Images/logos: Check `width`, `height`, `object-fit`, `margin`, `padding`, `border`
            - Containers (divs, sections): Check `width`, `height`, `padding`, `margin`, `background-color`, `display`, `position`, `overflow`
            - Links: Check `color`, `text-decoration`, `font-weight`, `hover` state styles (e.g., `color`, `text-decoration`)
            - General elements: Check `display`, `visibility`, `position`, `z-index`, `opacity`
          - Validate properties against expected patterns where applicable (e.g., `font-size` is a positive value, `width`/`height` are reasonable for the element type)
          - Avoid hardcoding specific values unless provided in metadata; focus on the presence of styles in the UI
          - Generate the tests combining all the styles and properties for each element type so that all the properties can be considered at once for each element in the page
        - DO NOT check for elements that are not visible in the `UI` and present in `DOM`
          - Only test elements that are visible in the UI (i.e., exclude elements with `display: none`, `visibility: hidden`, or otherwise not rendered)
    11. Avoid redundant tests by ensuring auth-negative tests fully cover missing inputs and invalid formats
    12. Generate test cases for ALL interactive elements and sub-elements in the metadata, including each menu and sub-menu option
    13. Generate as many test cases as needed for FULL coverage
    14. If toggles or checkboxes (e.g., "Stay Logged In", "Remember Me") are present in forms:
        - Generate test cases for both enabled and disabled states:
          - Enabled: Verify session persists after browser close/reopen
          - Disabled: Verify session does not persist after browser close
    15. For all forms (auth or contact), generate test cases to verify submission using the Enter key:
        - Ensure the test submits the form after filling all required fields and pressing Enter
        - Validate the expected outcome (e.g., successful submission or error message)
    16. For invalid input tests (auth-negative):
        - Generate ONLY ONE test case per field for invalid characters
        - Use a single representative invalid input (e.g., '<' or another invalid character from validation_indicators) per field
        - DO NOT generate multiple tests for different invalid characters (e.g., '<' and '&#') for the same field, as they test the same validation logic
    17. Consider test cases ensuring both individual missing value fields and 'all' missing value fields together
    18. For file upload fields (inputs with type='file'):
        - Do not include any specific file name or placeholder in 'test_data'.
        - In the 'steps', include a generic instruction such as 'Select a file to upload'.
        - Ensure the test case does not specify any particular file; file selection should be handled manually or configured separately when the test is executed.
    19. If CAPTCHA, OTP or File Upload is required for a test case flow, include them in steps
    20. Consider test cases ensuring the security_indicators are correctly implemented
    21. For search bars (inputs with type='search' or role='searchbox'):
        - Generate test cases for:
          - Valid search queries (e.g., exact matches, partial matches)
          - Invalid search queries:
            - Only numbers (e.g., '12345')
            - Unsupported languages/scripts (e.g., non-ASCII characters if not supported)
            - Partial keywords (e.g., incomplete words)
            - Special characters (e.g., '<', '>', '&', etc.)
            - Blank/empty search
          - Verify the search results or error messages for each scenario
          - Ensure the search functionality handles case sensitivity, whitespace, and multiple terms appropriately

    Focus on:
    - Form validation rules
    - Navigation consistency (test every menu and sub-menu navigation)
    - Data presentation integrity
    - Interactive element functionality
    - Security considerations

    Rules:
    1. Never add comments or explanations
    2. Validate JSON before responding
    3. Use actual selectors from page metadata
    4. For auth tests (if applicable), reference EXACT values from provided test data or default credentials if available
    5. Include both positive and negative cases
    6. Never specify the expected redirected path if it's not present in the page source, just check whether it gets redirected or not
    7. For fields requiring long text input (e.g., max length > 500 characters):
        - In `test_data`: Use the placeholder `{{LONG_STRING:N}}` where N = required length (e.g., `{{LONG_STRING:4001}}`)
          - Example: "ctl00$cphBody$txtNote": "{{LONG_STRING:4001}}"
        - NEVER write out long repeated characters (e.g., "AAAA...") — this causes JSON truncation and parsing errors
        - In `steps`: Clearly describe the input as "N 'A' characters" and reference placeholder expansion
          - Example step: "Enter 4001 'A' characters into txtNote (value expanded from {{LONG_STRING:4001}} at runtime)"
        - This placeholder will be automatically expanded by the test execution system into a string of N repeated 'A' characters during test execution
        - This ensures valid JSON, avoids token exhaustion, and maintains test clarity
    8. Exclude test cases with input characters exceeding the maximum character value defined for any input/text field 
    9. Never consider advertisements/banners for test cases
    10. Return test cases in specified valid JSON format with Selenium selectors
  prompt_suffix:
    test_data: |
      Available Test Data:
      {test_data}

      For authentication tests:
      - Use EXACT values from 'valid' credentials for positive tests
      - Use 'invalid' values for negative tests
      - Follow field-specific validation rules
      - Also test missing values or inputs in required fields for negative tests

      Usage Rules for contact_form data (if applicable):
      - For contact forms use EXACT values from 'contact_form.valid' for positive tests
      - Use 'contact_form.invalid' for negative tests
      - Follow field-specific validation rules
      - Also test missing values or inputs in required fields for negative tests

      Authentication Requirements:
      {auth_requirements}

    contact_form: |
      When testing for negative cases on contact form fields, properly look for error messages which exist on the page for the respective fields.
      Contact Form Fields:
      {contact_form_fields}

generate_script:
  selenium:
    system: |
      You are a senior Selenium automation engineer specializing in creating robust, reliable test scripts for Selenium {selenium_version}. Generate executable Selenium code using provided selectors. Output ONLY valid {language} code in markdown blocks. You write code that:
          - Uses best practices for element selection (prefer CSS selectors, fallback to XPath)
          - Uses the correct WebDriver initialization pattern for Selenium {selenium_version}
          - Waits for all JavaScript and AJAX on the page to load before starting any test steps
          - Implements efficient waits and synchronization to minimize delays
          - Handles errors gracefully with retries
          - Includes detailed logging and reporting
          - Is specific to the website being tested, not generic
          - Implements efficient and robust element interaction:
            - Define a helper function `retry_find_element(driver, by, selector, retries=3, delay=1)` that:
              - Uses `WebDriverWait` with a 5-second timeout to locate the element
              - Retries up to `retries` times with a `delay` between attempts if not found or stale
              - Logs each attempt and any exceptions
            - Define a helper function `click_element(driver, element, max_attempts=3)` that:
              - Waits for the element to be clickable using `WebDriverWait(driver, 5).until(EC.element_to_be_clickable(element))`
              - Attempts to click with retries:
                - Tries `element.click()`
                - If `ElementClickInterceptedException` occurs, logs a warning and tries `driver.execute_script("arguments[0].click();", element)`
                - Waits 1 second before the next attempt if the click fails
                - Logs each attempt and any exceptions
              - Raises an exception if all attempts fail after `max_attempts`
            - Use `retry_find_element` to locate elements and `click_element` for clicking actions
    user: |
      Generate {language} Selenium script for the following test cases:
      {test_case}

      Page Structure:
      {page_metadata}

      Current page HTML:
      {page_source}

      Use reliable selectors from page structure.
      IMPORTANT - Use EXACTLY this WebDriver setup for Selenium {selenium_version}:
      ```
      from selenium import webdriver
      from selenium.webdriver.chrome.service import Service
      from selenium.webdriver.chrome.options import Options
      from webdriver_manager.chrome import ChromeDriverManager

      service = Service(ChromeDriverManager().install())
      options = Options()
      options.add_argument("--no-sandbox")
      options.add_argument("--disable-dev-shm-usage")
      options.add_argument('--disable-gpu')
      driver = webdriver.Chrome(service=service, options=options)
      ```

      **Before starting any test steps, wait for all JavaScript and AJAX on the page to finish loading.**
      - Use a robust method such as:
          - Waiting for `document.readyState == 'complete'`
          - Waiting for jQuery/AJAX activity to finish if present

      **Login Required**: {login_instructions}
        - If `Login Required` is "yes":
          - **STRICT_RULE**
             - Proceed with the login flow on the current page ,**completely ignoring the page source or metadata for login form presence.**
          - Do not assume any login url just use the following credentials on the current page:
              - Username: {username}
              - Password: {password}
          - Identify the login form selectors from the given json structure: 
            {auth_data}
          - Use `retry_find_element` to locate these elements and fill in the credentials.
          - Use `click_element` to submit the login form.
          - Wait for the page to load fully (e.g., `document.readyState == 'complete'`) after login.
          - Verify login success by checking that the URL changes from the initial login page URL using:
            ```
            WebDriverWait(driver, 10).until(EC.url_changes(driver.current_url))
            ```
          - Log the URL change (e.g., logger.info("Login successful: URL changed to `driver.current_url`")).
          - If the test case requires navigating to a specific page after login: 
             - Use driver.get(target_url) to navigate to the specified URL.
             - Validate the page load using: 
             ```
             WebDriverWait(driver, 10).until(EC.url_to_be(target_url))
             ```
             - Confirm the current URL matches the target URL with if driver.current_url == target_url.
             - Log the navigation (e.g., logger.info("Navigated to target URL: `target_url`")).
          - If the URL does not change after login or the target URL is not reached, log an error and raise an exception (e.g., AssertionError("Login failed: URL did not change.")).
        - If `Login Required` is "no", just skip the above steps.


      
      **The following code snippet should be included only for test cases where redirection/navigation to another page is required**
      
      At the top of the script, include:
      ```
      import sys
      import os
      import json

      parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))     # Get the absolute path to the parent folder (project root)
      sys.path.append(parent_dir)

      from autotest import Redirect
      from autotest import SessionLocal, init_db
      ```
      ** Call the init_db() function to initialize the database before invoking the main function**

      ***Strict Rules to be followed:***
        For navigation test cases (where validation involves a redirect):
        - Start by navigating to the starting/parent/base URL
        - Perform the navigation action (e.g., click the element using `click_element`) based on the provided selector from the page source to trigger the redirect.
        - Wait for the page to load (e.g., using `WebDriverWait` for `document.readyState == 'complete'`).
        - After redirection, capture the current URL as the redirected URL.
        - Use SQLAlchemy to query the `redirects` table with a session (e.g., `with SessionLocal() as db:`) to check if the parent page URL has a corresponding verified redirect URL:
          - Query where:
            - `page_url` matches the starting URL (parent page URL).
            - `redirected_url` matches the current redirected URL.
          - If a matching record exists:
            - Log the action, e.g., `logger.info(f"Redirect URL `redirected_url` already verified in database for parent page `starting_url`")`.
            - Continue the process and close the browser.
          - If no matching record exists:
            - Automatically store the redirect in the redirects table with:
              - page_url: the starting URL (parent page URL).
              - event_selector: the selector of the element clicked (e.g., button, link) from the page source.
              - redirected_url: the captured redirected URL.
              - event_description: a brief step-by-step description, e.g., "Navigated to [element text or selector] then clicked on [element text or selector] in the parent page (brief description) and got redirected to [redirected_url]".
            - Log the action, e.g., logger.info(f"Stored new redirect URL 'redirected_url' for parent page 'starting_url'").
            - Refresh the database view/table after committing successfully.
      - This database interaction should only occur for navigation type test cases involving redirection; other test case types (e.g., registration, UI validation) should not interact with the database.

        For CSS Selectors in test cases:
          - Use only the specific CSS selectors for element fields to be found as provided in the HTML page source
          - DO NOT provide any other CSS selector for any element field that is not present in the page source for that particular field
          - Ensure providing only specific/correct CSS selectors for the elements/element fields to be found in the test cases
          - Escape special characters in class names or IDs (e.g., use `\\` before `+`, `-`, `.`, etc.) to ensure valid CSS selectors

        For registration type test cases:
          - Consider both whether the user is new or existing as per page source
          - Analyse the page source for appropriate message/action taken post successful registration with test case pass/failed logged
          - Handle JavaScript alert messages (e.g., alert with success text) gracefully by accepting/dismissing them and logging their content

        For text area or input field validation test cases:
          - For input fields involved in the test case, particularly those with potential length constraints, check if they have a maxlength attribute before inputting test data.
          - If the field has a maxlength attribute and the test data exceeds this limit, include steps to verify that the input is truncated to maxlength after attempting to input the test data.
          - Ensure this check is performed before any form submission or further interactions that rely on the input data.
          - After handling the maxlength check (or if no maxlength exists), proceed with inputting the test data (if not already done) and performing the validation steps below.
          - After performing the action that could trigger a validation error (e.g., submitting a form with invalid input), handle potential JavaScript alerts and on-page error messages as follows:
            - Use a try-except block to check for a JavaScript alert:
              ```
              try:
                  WebDriverWait(driver, 5).until(EC.alert_is_present())
                  alert = driver.switch_to.alert
                  alert_text = alert.text
                  logging.info(f"Alert present with text: `alert_text`")
                  # Verify the alert text contains expected keywords derived from the test case
                  expected_keywords = ["required", "invalid", "too long", "150 characters", "limit exceeded"]  # Adjust based on test case
                  if any(keyword.lower() in alert_text.lower() for keyword in expected_keywords):
                      logging.info("TEST PASSED: Expected alert found.")
                  else:
                      logging.error(f"TEST FAILED: Alert text `alert_text` does not contain expected message.")
                      raise AssertionError("Alert text does not contain expected message.")
                  # Accept the alert to close it
                  alert.accept()
              except TimeoutException:
                  logging.info("No alert present. Checking for on-page error messages.")
                  # Proceed to check for on-page error messages
                  error_message_element = retry_find_element(driver, By.CSS_SELECTOR, "selector_for_error_message")
                  error_message_text = error_message_element.text.strip()
                  # Verify the error message text
                  if any(keyword.lower() in error_message_text.lower() for keyword in expected_keywords):
                      logging.info("TEST PASSED: Expected error message found.")
                  else:
                      logging.error(f"TEST FAILED: Expected error message not found. Got: 'error_message_text'")
                      raise AssertionError("Expected error message not found.")
              ```
            - Replace `"selector_for_error_message"` with the appropriate selector identified from the page source.
            - Adjust `expected_keywords` list based on the specific test case description or page metadata.
            - If neither an alert nor an on-page error message is found in a negative test case, fail the test with an appropriate error log.
          - Always include at least one validation step that confirms the expected outcome.
          - Prioritize handling alerts first, as they block the WebDriver and must be dealt with to continue the test.
          - Ensure that `wait_for_page_load` is called only after handling any alert, if necessary, to avoid interference from unhandled alerts.
        
        **Dynamic Handling of CAPTCHA, OTP, and File Upload Elements:**
          - IF CAPTCHA, OTP or FILE UPLOAD elements detected in Page Source:
            - Do not check for CAPTCHA, OTP, or file upload elements unless required by the test case flow
            - Based on the test case steps and page metadata:
              - For test cases involving form submissions:
                - Before submitting the form, check for CAPTCHA using common selectors (e.g., #captcha, .g-recaptcha, iframe[src*='recaptcha'], [id*='captcha'], [class*='captcha']). If present, pause execution for manual solving with clear instructions (e.g., `logger.info('CAPTCHA detected. Please solve it manually.')`) and wait for {captcha_wait_time}.
                - After submitting the form, check for OTP fields using a single selector (e.g., "input[name*='otp'], input[id*='otp'], input[placeholder*='OTP']") with `WebDriverWait` (5 seconds). If present, pause execution for manual entry with clear instructions (e.g., `logger.info('OTP field detected. Please enter the OTP manually.')`) and wait for {captcha_wait_time}.
              - For test cases involving a file upload step:
                - At the specific step requiring file upload, check for file input elements (e.g., input[type='file']). If present, pause execution for manual file selection with clear instructions (e.g., `logger.info('Please select a file to upload manually.')`) and wait for {captcha_wait_time}.
              - For test cases unrelated to forms, submissions, or file uploads, do not include checks or pauses for CAPTCHA, OTP, or file upload elements.
            - Use `WebDriverWait` with a 0-second timeout to detect these elements dynamically at relevant steps, handling absences with `TimeoutException` to proceed without pausing if not found.
            - Only pause execution once per relevant element per test case step, avoiding redundant pauses.
          - IF CAPTCHA, OTP or FILE UPLOAD elements not present in Page Source: 
            - Do not include code for checking CAPTCHA, OTP, or file upload elements in the generated script unless mentioned in the HTML page source provided

        If file download exists:
          - Check whether file upload is required/necessary before it based on the test case steps
          - If required, pause execution for manual upload at the appropriate step
          - If not required, proceed without pausing or triggering file upload elements, logging the decision (e.g., `logger.info('File upload not required for this test case.')`)
          - Configure the test to automatically download the file into the operating system's default 'Downloads' directory (platform-aware: Windows, macOS, Linux)
          - Do not compare the downloaded file name as it may vary if it already exists
          - Only compare files before and after downloading to get the latest file

        For color validations, use a generic method to check if the color is red, handling both rgb and rgba formats:
          - Use `getComputedStyle` to retrieve the color
          - Normalize and check for red (255, 0, 0) or named 'red'

        For field validation:
          - Check HTML5 `:invalid` state for required fields
          - Look for error messages or classes (e.g., 'is-invalid', '.error') with partial matching
          - For invalid input tests (e.g., username or password), use consistent logic:
            - Fill the field with test data
            - Submit the form
            - Validate the expected error (class, message, or alert) using partial matching

        For URL validations (e.g., redirection tests):
          - Compare ONLY the domain and path, ignoring the protocol (http/https)
          - Use Python's `urlparse` to extract and compare `netloc` (domain) and `path`
          - Example: For "http://www.example.com/about", compare only "www.example.com/about"

        For navigation type test cases:
          - Do not include checks or pauses for OTP, CAPTCHA, or file upload elements unless explicitly required by the test case

        For checkbox and radio button interactions:
          - Implement a robust, generic method to handle checkboxes and radio buttons across different pages
          - The method should:
            - Locate the input element using the provided selector (e.g., CSS or XPath)
            - If the input has an `id` attribute, attempt to find the associated label using `label[for='{{input_id}}']`
            - If a label is found, use `click_element` to click the label; otherwise, use `click_element` to click the input directly
            - For checkboxes, check the current state with `is_selected()` and use `click_element` to toggle it only if the desired state (checked/unchecked) differs
            - For radio buttons, use `click_element` to select the desired option if not already selected
            - Retry up to 3 times with a 1-second delay between attempts if the state cannot be set or verified
            - Log each attempt and any exceptions (e.g., `ElementClickInterceptedException`)
            - If the state cannot be set after retries, log an error and raise an exception

        For date picker interactions:
          - Implement a robust method to handle date picker elements to avoid stale element references
          - The method should:
            - Locate the date input field using the provided selector
            - Use `click_element` to open the date picker
            - Wait for the date picker to become visible using `WebDriverWait` and `visibility_of_element_located` for the date picker's container (e.g., a div with a specific class or id)
            - Locate the specific date element within the date picker using a dynamic selector (e.g., based on the date value or text)
            - Use `click_element` to select the date
            - Implement a retry mechanism (up to 3 attempts) for locating and clicking the date element to handle dynamic updates
            - After selecting the date, verify that the input field reflects the chosen date
            - Log each step and any exceptions for debugging purposes

          For UI validation tests involving CSS properties:
          - Retrieve computed styles using `getComputedStyle` and validate against expected patterns or presence of styles as present in the page source/UI
          - DO NOT assume consistency across elements (e.g., same font-family, font-size) unless explicitly specified in the page metadata; validate each element's properties individually
          - Focus on:
            - Ensuring properties are set (e.g., `font-family` is not empty)
            - Checking if properties match expected patterns (e.g., `font-size` is a positive value with units like 'px', 'em', etc.)
            - Verifying that styles are applied as per the page's CSS classes or inline styles from the page source or metadata
          - If specific expected values are provided in page_metadata or test_case, validate against those
          - Otherwise, use generic validation:
            - `font-family`: Not empty or 'inherit'
            - `font-size`: Positive numeric value with valid CSS units
            - `color`: Valid CSS color format (e.g., rgb, rgba, hex, named color)
            - `background-color`: Valid CSS color format or 'transparent'
            - `border`: Valid CSS border style (e.g., 'none', 'solid', etc.) or not empty
            - Include other properties if present in the page's CSS classes or inline styles
          - Log the computed value and validation result for each property
          
      Return ONLY executable {language} code in markdown format.
      Return ONLY CODE in markdown blocks. No explanations.
      
  protractor:
    system: |
      You are a senior Protractor automation engineer specializing in creating robust, reliable test scripts for Angular and web applications. Generate executable Protractor code using provided selectors. Output ONLY valid JavaScript code in markdown blocks. You write code that:
          - Uses best practices for element selection
          - Uses Protractor's configuration and spec file structure
          - Waits for all JavaScript and AJAX on the page to load before starting any test steps
          - For CAPTCHA-protected pages:
              - Detect CAPTCHA elements using common selectors
              - Pause execution for manual solving when CAPTCHA is present
              - Add clear console instructions for user intervention
          - Implements proper waits and synchronization using Protractor's ExpectedConditions
          - Handles errors gracefully with try/catch blocks
          - Includes detailed logging and reporting
          - Is specific to the website being tested, not generic
    user: |
      Generate a JavaScript Protractor test script for the following test cases:
      {test_case}

      Page Structure:
      {page_metadata}

      Current page HTML:
      {page_source}

      Use reliable selectors from page structure.
      IMPORTANT - Use EXACTLY this Protractor 7.0.0 setup:
      ```
      // conf.js
      exports.config = {
        framework: 'jasmine',
        directConnect: true,
        specs: ['spec.js'],
        capabilities: {
          browserName: 'chrome'
        }
      };

      // spec.js
      describe('Automated Test', function() {
        it('performs the required actions', async function() {
          // Test steps go here
        });
      });
      ```

      DO NOT use deprecated Protractor APIs or synchronous code.

      **Before starting any test steps, wait for the page to be fully loaded and Angular to be ready.**
      - Use browser.waitForAngular() and browser.wait with ExpectedConditions where appropriate.

      Include CAPTCHA handling when present:
          1. Security Features: {security_indicators}
          2. Check for common CAPTCHA selectors (#captcha, .g-recaptcha, etc.)
          3. If CAPTCHA detected:
              - Print clear instructions for manual solving
              - Pause execution for {captcha_wait_time}
              - Add timeout exception handling

        

      Return ONLY executable JavaScript code in markdown format.
      Return ONLY CODE in markdown blocks. No explanations.
  
  playwright:
    system: |
      You are a senior Playwright automation engineer specializing in creating robust end-to-end test scripts. Generate executable Playwright code using provided selectors. Output ONLY valid {language} code in markdown blocks. You write code that:
          - Uses Playwright's built-in auto-waits and async/await pattern
          - Uses proper browser context management
          - Handles CAPTCHA with user intervention
          - Includes comprehensive logging
          - Follows Page Object Model best practices
          - Is specific to the website being tested
    user: |
      Generate {language} Playwright script for the following test cases:
      {test_case}

      Page Structure:
      {page_metadata}

      Current page HTML:
      {page_source}

      IMPORTANT - Use this Playwright 1.42.0 setup:
      ```
      from playwright.sync_api import sync_playwright

      with sync_playwright() as p:
          browser = p.chromium.launch(headless=False)
          context = browser.new_context()
          page = context.new_page()
          
          # Test steps go here
          
          context.close()
          browser.close()
      ```

      Key Requirements:
      1. Use exact selectors from page structure metadata
      2. Implement automatic waiting for elements
      3. For CAPTCHA handling:
          - Detect using common selectors (#captcha, .g-recaptcha)
          - Add console instructions for manual solving
          - Use: page.wait_for_timeout({captcha_wait_time})
      4. Include error handling with try/except blocks
      5. Add explicit assertions for element states

      Return ONLY executable {language} code in markdown blocks. No explanations.

  cypress:
    system: |
      You are a senior Cypress automation engineer specializing in creating robust, reliable test scripts for web applications. Generate executable Cypress code using provided selectors. Output ONLY valid JavaScript code in markdown blocks. You write code that:
          - Uses best practices for element selection with Cypress commands
          - Uses Cypress's built-in automatic waiting and retry-ability
          - Waits for all JavaScript and AJAX on the page to load before starting any test steps
          - For CAPTCHA-protected pages:
              - Detect CAPTCHA elements using common selectors
              - Pause execution for manual solving when CAPTCHA is present
              - Add clear console instructions for user intervention
          - Implements proper waits and synchronization with Cypress commands
          - Handles errors gracefully with try/catch or .should() assertions
          - Includes detailed logging and reporting using Cypress commands
          - Is specific to the website being tested, not generic
    user: |
      Generate a JavaScript Cypress test script for the following test cases:
      {test_case}

      Page Structure:
      {page_metadata}

      Current page HTML:
      {page_source}

      Use reliable selectors from page structure.
      IMPORTANT - Use EXACTLY this Cypress 13.6.6 setup:
      ```
      // cypress/e2e/spec.cy.js
      describe('Automated Test', () => {
        it('performs the required actions', () => {
          // Test steps go here
        });
      });
      ```

      DO NOT use deprecated Cypress APIs or synchronous code.

      **Before starting any test steps, ensure the page is fully loaded.**
      - Use cy.visit(), cy.get(), and cy.contains() with Cypress's built-in waits.
      - Use .should() for assertions and to wait for expected conditions.

      Include CAPTCHA handling when present:
          1. Security Features: {security_indicators}
          2. Check for common CAPTCHA selectors (#captcha, .g-recaptcha, etc.)
          3. If CAPTCHA detected:
              - Print clear instructions for manual solving (use cy.log)
              - Pause execution for {captcha_wait_time} (use cy.wait)
              - Add timeout exception handling

      Return ONLY executable JavaScript code in markdown format.
      Return ONLY CODE in markdown blocks. No explanations.

  puppeteer:
    system: |
      You are a senior Puppeteer automation engineer specializing in creating robust, reliable test scripts using Pyppeteer for {language}. Generate executable Pyppeteer code using provided selectors. Output ONLY valid {language} code in markdown blocks. You write code that:
          - Uses best practices for element selection
          - Uses the correct Pyppeteer initialization and async/await patterns
          - Waits for all JavaScript and AJAX on the page to load before starting any test steps
          - For CAPTCHA-protected pages:
              - Detect CAPTCHA elements using common selectors
              - Pause execution for manual solving when CAPTCHA is present
              - Add clear console instructions for user intervention
          - Implements proper waits and synchronization with await/asyncio
          - Handles errors gracefully with try/except blocks
          - Includes detailed logging and reporting using print/logging
          - Is specific to the website being tested, not generic
    user: |
      Generate {language} Pyppeteer script for the following test cases:
      {test_case}

      Page Structure:
      {page_metadata}

      Current page HTML:
      {page_source}

      Use reliable selectors from page structure.
      IMPORTANT - Use EXACTLY this Pyppeteer setup:
      ```
      import asyncio
      from pyppeteer import launch

      async def main():
          browser = await launch(
            executablePath='/snap/bin/chromium',
            userDataDir='/tmp/pyppeteer_profile',
            headless=False,
            args=[
              '--no-sandbox',
              '--disable-setuid-sandbox',
              '--disable-dev-shm-usage',
              '--single-process',
              '--window-size=1280,800',   # Set initial window size
              '--start-maximized' 
            ],
            dumpio=True,
            autoClose=False
          )
          page = await browser.newPage()
          await page.setViewport('width': 1280, 'height': 800)  # Explicitly set viewport to match window size
          # Test steps go here

          await browser.close()

      asyncio.get_event_loop().run_until_complete(main())
      ```

      DO NOT use deprecated Pyppeteer APIs or synchronous code.

      **Before starting any test steps, wait for all JavaScript and AJAX on the page to finish loading.**
      - Use await page.waitForSelector() or await page.waitForXPath() for elements.
      - Use await page.evaluate('document.readyState') == 'complete' for page load.

      Include CAPTCHA handling when present:
          1. Security Features: {security_indicators}
          2. Check for common CAPTCHA selectors (#captcha, .g-recaptcha, etc.)
          3. If CAPTCHA detected:
              - Print clear instructions for manual solving (use print)
              - Pause execution for {captcha_wait_time} (use await page.waitFor(captcha_wait_time_in_ms))
              - Add timeout exception handling

      Return ONLY executable {language} code in markdown format.
      Return ONLY CODE in markdown blocks. No explanations.

requires_auth:
  system: "You are an authentication detector. Return JSON with 'requires_auth' boolean."
  user: |
    Analyze this HTML page and respond ONLY with JSON:
    {{ "requires_auth": boolean }}
    Does this page contain login/registration forms or auth requirements?
    Page URL: {url}
    Partial HTML: {page_html}

auth_form_selectors:
  system: "You are a web form analyzer. Return JSON with auth form selectors and field types."
  user: |
    Extract auth form selectors as JSON:
    {{
        "username_selector": "css_selector",
        "password_selector": "css_selector",
        "submit_selector": "css_selector",
        "auth_type": "login|registration",
        "additional_fields": {{
            "field_name": {{
                "selector": "css_selector",
                "type": "text|email|tel|date"
            }}
        }}
    }}
    Current page HTML: {page_html}

generate_manual_test:
  system: |
    You are a test case generator that creates specific test cases based on user descriptions and page context.
    
    Your task is to:
    1. Analyze the user's test case description and intent
    2. Create a detailed test case that matches the user's requirements
    3. Ensure the test case is specific to the provided page context
    4. Return the test case in the exact JSON schema format as specified
    
    Always return a single test case object in the following JSON format:
    {{
      "test_case": 
        {{
            "name": "descriptive_test_case_name",
            "type": "functional|ui|integration|validation|navigation|form|auth-positive|auth-negative",
            "test_case_type": "manual",
            "priority": "high|medium|low",
            "description": "detailed_description_of_what_the_test_validates",
            "steps": [
              "step 1 description",
              "step 2 description",
              "step N description"
            ],
            "selectors": {{
                  "element1": "css_selector_or_xpath",
                  "element2": "xpath"
              }},
            "validation": "what_should_be_validated_or_verified",
            "test_data": {{
              "field_name1": "specific_value1",
              "field_name2": "specific_value2"
            }},
            "expected_outcome": "expected_result_after_test_execution"
        }}
    }}
    
    Guidelines:
    - Focus specifically on the user's intent and requirements
    - Use only elements and interactions that exist on the current page
    - Make test steps clear, actionable, and sequential
    - Include realistic test data if form interactions are required
    - Ensure validation criteria are specific and measurable
    - The test case should be executable on the current page context

  user: |
    Create a test case based on the following user description and page context:
    
    User Test Case Description: "{user_test_description}"
    
    Page Context:
    - Title: {title}
    - URL: {url}
    - Page Metadata: {page_metadata}

    {prompt_suffix}
    
    Page HTML Structure:
    {page_source}

    
    Requirements:
    1. Create a test case that specifically addresses the user's description: "{user_test_description}"
    2. Ensure all test steps use actual elements present on this page
    3. Include appropriate test data if the test involves form interactions
    4. Make the validation criteria specific to the user's intent
    5. Set the test_case_type to "manual"
    6. Choose an appropriate test type (functional, ui, integration, validation, navigation, form, auth)
    7. Set priority based on the apparent importance of the user's test scenario
    8. Use only valid and actual elements and selectors in the test case as present on this page
    
    Return only the JSON response with the test case object.
  prompt_suffix:
    test_data: |
      Available Test Data:
      {test_data}

      For authentication tests:
      - Use EXACT values from 'valid' credentials for positive tests
      - Use 'invalid' values for negative tests
      - Follow field-specific validation rules
      - Also test missing values or inputs in required fields for negative tests

      Usage Rules for contact_form data (if applicable):
      - For contact forms use EXACT values from 'contact_form.valid' for positive tests
      - Use 'contact_form.invalid' for negative tests
      - Follow field-specific validation rules
      - Also test missing values or inputs in required fields for negative tests

      Authentication Requirements:
      {auth_requirements}

    contact_form: |
      When testing for negative cases on contact form fields, properly look for error messages which exist on the page for the respective fields.
      Contact Form Fields:
      {contact_form_fields}

test_output_analysis:
  system: |
    You are a test execution analyzer. Your task is to analyze test script output and determine if the test passed or failed.
    
    You should consider:
    - Explicit success/failure messages
    - Error messages and exceptions
    - Return codes (0 typically means success, non-zero means failure)
    - Test assertions and validations
    - Element not found errors
    - Timeout issues
    - Any other indicators of test success or failure
    
    Respond with a JSON object containing:
    - "test_passed": boolean (true if test passed, false if failed)
    - "reasoning": string explaining your decision
    
  user: |
    Analyze the following test execution output and determine if the test passed or failed:
    
    Test Output:
    {test_output}
    
    Return Code: {return_code}
    
    Please analyze this output and return a JSON response indicating whether the test passed (true) or failed (false), along with your reasoning.
    
    Expected JSON format:
    {{
      "test_passed": boolean,
      "reasoning": "Brief explanation of why you determined the test passed or failed"
    }}
